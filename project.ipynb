{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize MongoDB client\n",
    "See README.md for setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.parse import quote_plus\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "username = quote_plus('common')\n",
    "password = quote_plus(os.environ.get('MONGODB_PASSWORD'))\n",
    "uri = f\"mongodb+srv://{username}:{password}@playervaluations.v7jevdf.mongodb.net/?retryWrites=true&w=majority\"\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import json\\n\\ndb = client[\\'player_valuations\\']\\ncollection = db[\\'players\\']\\nplayer = collection.find_one({\\'player_id\\': 10})\\n\\n# Print the result\\nif player:\\n    print(\"Player found:\", json.dumps(player, indent=4, default=str))\\nelse:\\n    print(\"No player found with player_id\", 65)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import json\n",
    "\n",
    "db = client['player_valuations']\n",
    "collection = db['players']\n",
    "player = collection.find_one({'player_id': 10})\n",
    "\n",
    "# Print the result\n",
    "if player:\n",
    "    print(\"Player found:\", json.dumps(player, indent=4, default=str))\n",
    "else:\n",
    "    print(\"No player found with player_id\", 65)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, MapType, StringType, IntegerType, DoubleType\n",
    "\n",
    "db = client['player_valuations']\n",
    "collection = db['players']\n",
    "res = collection.find()\n",
    "\n",
    "df = pd.DataFrame(list(res))\n",
    "df.drop(\"_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"first_name\", StringType(), True),\n",
    "    StructField(\"last_name\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"last_season\", IntegerType(), True),\n",
    "    StructField(\"current_club_id\", IntegerType(), True),\n",
    "    StructField(\"player_code\", StringType(), True),\n",
    "    StructField(\"country_of_birth\", StringType(), True),\n",
    "    StructField(\"city_of_birth\", StringType(), True),\n",
    "    StructField(\"country_of_citizenship\", StringType(), True),\n",
    "    StructField(\"date_of_birth\", StringType(), True),\n",
    "    StructField(\"sub_position\", StringType(), True),\n",
    "    StructField(\"position\", StringType(), True),\n",
    "    StructField(\"foot\", StringType(), True),\n",
    "    StructField(\"height_in_cm\", DoubleType(), True),\n",
    "    StructField(\"contract_expiration_date\", StringType(), True),\n",
    "    StructField(\"agent_name\", StringType(), True),\n",
    "    StructField(\"image_url\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"current_club_domestic_competition_id\", StringType(), True),\n",
    "    StructField(\"current_club_name\", StringType(), True),\n",
    "    StructField(\"market_value_in_eur\", DoubleType(), True),\n",
    "    StructField(\"highest_market_value_in_eur\", DoubleType(), True),\n",
    "    StructField(\"valuations\", ArrayType(StructType([\n",
    "        StructField(\"player_id\", IntegerType(), True),\n",
    "        StructField(\"date\", StringType(), True),\n",
    "        StructField(\"datetime\", StringType(), True),\n",
    "        StructField(\"dateweek\", StringType(), True),\n",
    "        StructField(\"market_value_in_eur\", IntegerType(), True),\n",
    "        StructField(\"current_club_id\", IntegerType(), True),\n",
    "        StructField(\"player_club_domestic_competition_id\", StringType(), True),\n",
    "    ]), True), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting a spark session and extracting the raw data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "player_valuation_df=ss.createDataFrame(df, schema = schema)\n",
    "appearances_df = ss.read.csv(\"raw_data\\\\transfermarkt\\\\appearances.csv\", header=True, inferSchema=True)\n",
    "games_df = ss.read.option(\"multiline\",\"true\").json(\"raw_data\\\\transfermarkt\\\\games.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "player_valuation_df = player_valuation_df.drop(*[\"image_url\", \"url\", \"name\", \"player_code\"])\n",
    "player_valuation_df = player_valuation_df.withColumns({\n",
    "    \"current_club_id\": when(player_valuation_df[\"last_season\"] != 2023, -1).otherwise(player_valuation_df[\"current_club_id\"]),\n",
    "    \"current_club_domestic_competition_id\": when(player_valuation_df[\"last_season\"] != 2023, \"-1\").otherwise(player_valuation_df[\"current_club_domestic_competition_id\"]),\n",
    "    \"current_club_name\": when(player_valuation_df[\"last_season\"] != 2023, \"Retired\").otherwise(player_valuation_df[\"current_club_name\"]),\n",
    "    \"market_value_in_eur\": when(player_valuation_df[\"last_season\"] != 2023, 0).otherwise(player_valuation_df[\"market_value_in_eur\"])\n",
    "})\n",
    "\n",
    "games_df = games_df.drop(*[\"url\", \"aggregate\", \"home_club_formation\", \"away_club_formation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max market value player in 2023. If there are many with the same max value take them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------+\n",
      "|first_name| last_name|market_value_in_eur|\n",
      "+----------+----------+-------------------+\n",
      "|    Kylian|    Mbapp√©|          180000000|\n",
      "|    Erling|   Haaland|          180000000|\n",
      "|      Jude|Bellingham|          180000000|\n",
      "+----------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col, expr\n",
    "\n",
    "valuations = player_valuation_df.select(\"valuations\")\n",
    "flattened_valuations = valuations.select(explode(\"valuations\").alias(\"valuation\"))\n",
    "valuations2023 = flattened_valuations.filter(\"substring(valuation.date, 1, 4) = '2023'\")\n",
    "max_market_value_players_2023 = valuations2023\\\n",
    "    .select(\"valuation.*\").groupBy(\"player_id\").max(\"market_value_in_eur\")\\\n",
    "    .withColumnRenamed(\"max(market_value_in_eur)\", \"market_value_in_eur\")\\\n",
    "    .join(player_valuation_df.select(\"player_id\", \"first_name\", \"last_name\"), on=\"player_id\", how=\"inner\")\\\n",
    "    .orderBy('market_value_in_eur', ascending=False)\\\n",
    "    .select(\"first_name\", \"last_name\", \"market_value_in_eur\")\n",
    "\n",
    "max_value = max_market_value_players_2023.select(\"market_value_in_eur\").first()[\"market_value_in_eur\"]\n",
    "\n",
    "max_value_players = max_market_value_players_2023.filter(col(\"market_value_in_eur\") == max_value)\n",
    "\n",
    "max_value_players.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing the MongoDB client and the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"client.close()\n",
    "ss.stop()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
